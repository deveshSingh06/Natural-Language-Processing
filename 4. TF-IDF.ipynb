{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF(Term Frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is defined for a word w<sub>i</sub> in a **document d<sub>i</sub>**.\n",
    "- It is defined as:\n",
    "\n",
    "$$\\text{TF($w_{i}$, $d_{i}$)} = \\frac{\\text{Number of occurrences of the word $w_{i}$}}{\\text{Total number of words in the document $d_{i}$}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Term frequency of a word w<sub>i</sub> in a document d<sub>i</sub> lies between 0 and 1, i.e \n",
    "> 0 <= TF(w<sub>i</sub>, d<sub>i</sub>) <= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since 0 <= TF(w<sub>i</sub>, d<sub>i</sub>) <= 1, TF(w<sub>i</sub>, d<sub>i</sub>) can be thought of as a probability of the word w<sub>i</sub> in document d<sub>i</sub>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDF(Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is defined for a word w<sub>i</sub> in the **document corpus D<sub>c</sub>**.\n",
    "- It is defined as:\n",
    "\n",
    "$$\\text{IDF($w_{i}$, $D_{c}$)} = \\log{\\frac{N}{\\text{$n_{i}$}}}$$\n",
    "<center>where N = Total number of documents</center>\n",
    "\n",
    "<center>$n_{i}$ = Number of documents in which the word w<sub>i</sub> occurs</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since $n_{i}$ <= N (always), this implies $\\frac{N}{\\text{$n_{i}$}}$ >= 1 (always). Hence, $$\\text{IDF($w_{i}$, $D_{c}$)} = \\log{\\frac{N}{\\text{$n_{i}$}} >= 0 \\text{ (Always)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the above relations we can see that **if $n_{i}$ increases, IDF decreases and vice-versa**.\n",
    "- That means if the word $w_{i}$ is more frequent, IDF will be small and if the word $w_{i}$ is rare then IDF will be large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this scheme, the value of a dimension of the vector $v_{i}$ corresponding to a document $d_{i}$ is calculated as:\n",
    "\n",
    "$$\\text{TF($w_{i}$, $d_{i}$)}*\\text{IDF($w_{i}$, $D_{c}$)}$$\n",
    "\n",
    "- Usage example: Let there be 6 dimensions in a vector $v_{i}$ and every dimension represents a unique word as depicted below:\n",
    "\n",
    "| w<sub>1</sub> |  w<sub>2</sub>  |  w<sub>3</sub>  | w<sub>4</sub>  | w<sub>5</sub>  |w<sub>6</sub>  |\n",
    "| --- |--- | --- | --- |--- |--- |\n",
    "|  |  |  |  |  |  |  |  |  |  |  |  |\n",
    "\n",
    "- Then the value of the dimension corresponding to, say w<sub>4</sub>, is calculated as:\n",
    "\n",
    "$$\\text{TF($w_{4}$, $d_{i}$)}*\\text{IDF($w_{4}$, $D_{c}$)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TF-IDF gives **more importance to rarer words in the document corpus.**\n",
    "- Also, tf-idf gives **more importance to frequent words in a document.**\n",
    "- This scheme doesn't consider the semantic meaning of words. For example the words 'tasty' and 'delicious' will have different dimensions, though they are semantically same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
